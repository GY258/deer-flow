#!/usr/bin/env python3
"""
åŸºçº¿å¯¹ç…§æµ‹è¯•ï¼šç›´æ¥æµ‹è¯• OpenAI API çš„æµå¼è¾“å‡º

è¿™ä¸ªè„šæœ¬ç”¨äºéªŒè¯ OpenAI API æœ¬èº«æ˜¯å¦æ”¯æŒé€ token æµå¼è¾“å‡ºã€‚
å¦‚æœè¿™é‡Œä¹Ÿæ— æ³•æµå¼è¾“å‡ºï¼Œé—®é¢˜åœ¨æ¨¡å‹æˆ– SDKï¼›å¦‚æœè¿™é‡Œå¯ä»¥æµå¼è¾“å‡ºï¼Œé—®é¢˜åœ¨ LangGraph/æœåŠ¡ç«¯ã€‚
"""

import os
import sys
import time
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

from openai import OpenAI
from src.config import load_yaml_config

def test_openai_direct_stream():
    """ç›´æ¥ä½¿ç”¨ OpenAI SDK æµ‹è¯•æµå¼è¾“å‡º"""
    print("=" * 60)
    print("åŸºçº¿æµ‹è¯•ï¼šç›´æ¥è°ƒç”¨ OpenAI API (è·³è¿‡ LangGraph/æœåŠ¡ç«¯)")
    print("=" * 60)
    
    # ä»é…ç½®æ–‡ä»¶è¯»å– API é…ç½®
    conf_path = project_root / "conf.yaml"
    if not conf_path.exists():
        print(f"âŒ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {conf_path}")
        return
    
    conf = load_yaml_config(str(conf_path))
    basic_model = conf.get("BASIC_MODEL", {})
    
    api_key = basic_model.get("api_key") or os.getenv("OPENAI_API_KEY")
    base_url = basic_model.get("base_url", "https://api.openai.com/v1")
    model = basic_model.get("model", "gpt-4o-mini")
    
    if not api_key:
        print("âŒ æœªæ‰¾åˆ° API keyï¼Œè¯·æ£€æŸ¥ conf.yaml æˆ– OPENAI_API_KEY ç¯å¢ƒå˜é‡")
        return
    
    print(f"ğŸ“‹ é…ç½®ä¿¡æ¯:")
    print(f"   Model: {model}")
    print(f"   Base URL: {base_url}")
    print(f"   API Key: {api_key[:20]}...")
    print()
    
    # åˆ›å»º OpenAI å®¢æˆ·ç«¯
    client = OpenAI(
        api_key=api_key,
        base_url=base_url
    )
    
    print("ğŸš€ å¼€å§‹æµå¼è¯·æ±‚...")
    print("-" * 60)
    
    try:
        # æµå¼è¯·æ±‚
        stream = client.chat.completions.create(
            model=model,
            messages=[{"role": "user", "content": "count to 10 slowly"}],
            stream=True,
        )
        
        print("ğŸ“¥ æ¥æ”¶åˆ°æµå¼å“åº”ï¼Œå¼€å§‹é€ token è¾“å‡ºï¼š")
        print()
        
        token_count = 0
        start_time = time.time()
        first_token_time = None
        
        for chunk in stream:
            # delta æ˜¯ ChoiceDelta å¯¹è±¡ï¼Œä¸æ˜¯å­—å…¸ï¼Œéœ€è¦ç›´æ¥è®¿é—®å±æ€§
            delta = chunk.choices[0].delta if chunk.choices else None
            content = delta.content if delta and hasattr(delta, 'content') else ""
            if content:
                if first_token_time is None:
                    first_token_time = time.time()
                    first_token_delay = first_token_time - start_time
                    print(f"[TTFB: {first_token_delay:.2f}s] ", end="", flush=True)
                
                print(content, end="", flush=True)
                token_count += 1
                
                # æ¯ä¸ª token ä¹‹é—´æ·»åŠ å°å»¶è¿Ÿä»¥ä¾¿è§‚å¯Ÿ
                time.sleep(0.01)
        
        print()
        print()
        print("-" * 60)
        
        if first_token_time:
            total_time = time.time() - start_time
            streaming_duration = time.time() - first_token_time
            print(f"âœ… æµ‹è¯•å®Œæˆ")
            print(f"   æ€» token æ•°: {token_count}")
            print(f"   é¦– token å»¶è¿Ÿ (TTFB): {first_token_delay:.2f}s")
            print(f"   æ€»è€—æ—¶: {total_time:.2f}s")
            print(f"   æµå¼ä¼ è¾“è€—æ—¶: {streaming_duration:.2f}s")
            print()
            
            # åˆ¤æ–­æ˜¯å¦çœŸçš„åœ¨æµå¼è¾“å‡º
            if token_count > 1 and first_token_delay < total_time * 0.5:
                print("âœ… ç»“è®ºï¼šæ¨¡å‹ç«¯ç¡®å®åœ¨é€ token æ¨é€ï¼ˆæµå¼è¾“å‡ºæ­£å¸¸ï¼‰")
                print("   â†’ å¦‚æœ LangGraph ä¸­ä¸æ˜¯æµå¼çš„ï¼Œé—®é¢˜åœ¨ LangGraph/æœåŠ¡ç«¯")
            elif first_token_delay > total_time * 0.8:
                print("âš ï¸  ç»“è®ºï¼šæ¨¡å‹ç«¯å¯èƒ½æ˜¯ä¸€æ¬¡æ€§è¿”å›ï¼ˆå¤§éƒ¨åˆ†å†…å®¹åœ¨æœ€åï¼‰")
                print("   â†’ é—®é¢˜å¯èƒ½åœ¨æ¨¡å‹æˆ– SDK é…ç½®")
            else:
                print("âš ï¸  ç»“è®ºï¼šæµå¼è¾“å‡ºè¡¨ç°å¼‚å¸¸ï¼Œéœ€è¦è¿›ä¸€æ­¥æ’æŸ¥")
        else:
            print("âŒ æœªæ”¶åˆ°ä»»ä½• token å†…å®¹")
            
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    test_openai_direct_stream()

